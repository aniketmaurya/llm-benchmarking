{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31644638-a09f-4e7b-b4a7-2883e6ce10f1",
   "metadata": {},
   "source": [
    "# Efficient Initialization of Large Models\n",
    "\n",
    "* [Blog](https://lightning.ai/pages/community/efficient-initialization-of-large-models/)\n",
    "\n",
    "We will be using `EleutherAI/pythia-1b` for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bda0f42-0e47-4140-9e77-f8bcfb780e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1fd0ec9-6b67-4646-a808-56f2f3be3179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lit_gpt import GPT, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f221823c-a468-45c2-88fd-e80021835edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"lit-gpt/checkpoints/EleutherAI/pythia-1b/lit_model.pth\"\n",
    "model_name = \"pythia-1b\"\n",
    "checkpoints = torch.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f6979-7eeb-4787-86ca-be6d2904d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "model = GPT.from_name(model_name)\n",
    "model.load_state_dict(checkpoints)\n",
    "print(f\"Time to load model: {time.time() - t0:.02f} seconds.\")\n",
    "print(\"This is your old nn.Module:\", isinstance(model, torch.nn.Module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015dc9a3-cb24-47be-ad34-42107fd70fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d988b615-d493-4e96-a8c2-205534175d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load model: 7.44 seconds.\n"
     ]
    }
   ],
   "source": [
    "fabric = L.Fabric(accelerator=accelerator)\n",
    "t0 = time.time()\n",
    "with fabric.device:\n",
    "    model = GPT.from_name(model_name)\n",
    "model.load_state_dict(checkpoints)\n",
    "print(f\"Time to load model: {time.time() - t0:.02f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89155462-5b66-46d0-bfeb-411e1489ea6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5d402e4-81c9-484a-9543-46ca3c7979da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load model: 9.66 seconds.\n"
     ]
    }
   ],
   "source": [
    "fabric = L.Fabric(accelerator=accelerator, precision=\"16-true\")\n",
    "t0 = time.time()\n",
    "with fabric.init_module():\n",
    "    model = GPT.from_name(model_name)\n",
    "model.load_state_dict(checkpoints)\n",
    "print(f\"Time to load model: {time.time() - t0:.02f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f955366b-7156-4c5d-8705-ae8a3d7b58de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd74c4b9-79f6-4d74-932b-38c5b6cd17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(Path(\"lit-gpt/checkpoints/EleutherAI/pythia-1b\"))\n",
    "\n",
    "prompt = \"Hello, my name is\"\n",
    "encoded = tokenizer.encode(prompt)\n",
    "prompt_length = encoded.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab8770-f92a-411a-a0c6-6133b0d609f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
