{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bda0f42-0e47-4140-9e77-f8bcfb780e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1fd0ec9-6b67-4646-a808-56f2f3be3179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lit_gpt import GPT, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af56524f-2cfb-4c67-9af5-4131802394ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_device(model):\n",
    "    return next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f221823c-a468-45c2-88fd-e80021835edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/data/aniket/meta-llama/Llama-2-7b-chat-hf/lit_model.pth\"\n",
    "checkpoint_dir = \"/data/aniket/meta-llama/Llama-2-7b-chat-hf\"\n",
    "model_name = \"Llama-2-7b-chat-hf\"\n",
    "checkpoints = torch.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5d402e4-81c9-484a-9543-46ca3c7979da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 0.00 GB\n",
      "Time to load model: 14.08 seconds.\n",
      "Memory used: 13.48 GB\n"
     ]
    }
   ],
   "source": [
    "fabric = L.Fabric(accelerator=\"gpu\", precision=\"bf16-true\")\n",
    "\n",
    "print(f\"Memory used: {torch.cuda.max_memory_reserved() / 1e9:.02f} GB\")\n",
    "t0 = time.time()\n",
    "with fabric.init_module():\n",
    "    model = GPT.from_name(model_name)\n",
    "    model.load_state_dict(checkpoints)\n",
    "print(f\"Time to load model: {time.time() - t0:.02f} seconds.\")\n",
    "print(f\"Memory used: {torch.cuda.max_memory_reserved() / 1e9:.02f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1d23fe2-7059-4956-960a-77897bc70bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(32000, 4096)\n",
       "    (h): ModuleList(\n",
       "      (0-31): 32 x Block(\n",
       "        (norm_1): RMSNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (attn): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): RMSNorm()\n",
       "        (mlp): LLaMAMLP(\n",
       "          (fc_1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (fc_2): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c41f629a-4cf4-4a47-b912-77082f0bc153",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(Path(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "727d88da-ae20-44e1-b1dd-f20fc197e414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 13.48 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory used: {torch.cuda.max_memory_reserved() / 1e9:.02f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3a74820-612c-4174-b771-6583be973a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "\n",
    "There's a llama in my garden ðŸ˜± What should I do? [/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a122b3c-706b-43ff-b61b-b513f6e22bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 159])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with fabric.device:\n",
    "    encoded = tokenizer.encode([prompt])\n",
    "\n",
    "prompt_length = encoded.size(0)\n",
    "encoded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf3a1246-af15-40a2-95d9-b1c8a9849b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 14.49 GB\n"
     ]
    }
   ],
   "source": [
    "logits = model(encoded, max_seq_length=512)\n",
    "model.reset_cache()\n",
    "print(f\"Memory used: {torch.cuda.max_memory_reserved() / 1e9:.02f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e04fc48-ea12-40fd-85e7-681c8bc7734b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nobody:00 What1MBOP What\n",
      "' a  A friendlyful, knowledge assistant. How ready questions iffully and possible, and also mind and I I goal will be be any harmful or unethical, dangerousist, toist, toxic, dangerous or or illegal content. I ref that your responses are freeally unbiased and positive in nature, I</I you user is not make sense sense or please is n clearual correcterent, please why in of providing it that relevant.\n",
      " a are't know the answer to a question, say say't make an information or Instead\n",
      "</sysS></\n",
      "Howfores a lotama named the kitchen. Canï¿½ï¿½ï¿½ What should I do?</ï¿½ss Thank\n"
     ]
    }
   ],
   "source": [
    "decoded = tokenizer.decode(logits[0].softmax(-1).argmax(-1))\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6926c9d-b5a0-4790-b01d-e8bfd0958b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c60fc-0527-4575-8337-5de71d6a0102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cfe6cab-fd1e-4009-b867-f085a97f458b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 49, 32000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = logits[..., :-1, :]\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9f684193-e15d-4885-aa6b-7501da4a99dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([98, 32000])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = logits.reshape(-1, logits.size(-1))\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b52b87f-56ac-4c90-8a4d-5e4102205efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits[..., :-1, :], targets[..., 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab8770-f92a-411a-a0c6-6133b0d609f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe81bfa-3aad-4673-b998-d9ee88dad7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
